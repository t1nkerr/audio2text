# 148: 访谈它石创始人陈亦伦：具身的三道曙光和第一道关卡
# Published: 2026-01-16 00:15
# Transcribed with Gemini 3 Flash

这是一份针对《晚点聊 LateTalk》第 148 期访谈它石智航创始人陈亦伦的逐字稿转录。

---

[00:00] **【程曼祺】** 欢迎收听晚点聊，我是曼祺。今天的嘉宾是它石智航的创始人陈亦伦。他曾担任大疆创新的机器视觉总工程师，以及华为自动驾驶部门的首席科学家。2021 年，在智能辅助驾驶爆发的前夕，陈亦伦在华为带团队开始采集大量真实的驾驶数据，用深度学习替代了过去自动驾驶常用的那种规则方法。他当时用 3 万行代码做了过去 200 万行代码才能做的事。这也是业界第一批探索“端到端”智能驾驶的尝试。

[01:15] **【陈亦伦】** 大家好，我是陈亦伦。很高兴来到晚点聊。

[01:18] **【程曼祺】** 亦伦，其实大家对你的简历非常好奇。你从大疆到华为，再到清华 AIR，最后选择在 2025 年初创立它石智航。而且听说你们刚起步就拿到了超过 2.4 亿美元的融资，创下了中国具身智能领域的首轮融资记录。我们今天就想聊聊，到底是什么让你觉得“具身智能”的那个钥匙已经找到了？

[01:45] **【陈亦伦】** 嗯，其实这把钥匙我在 2021 年的时候就觉得隐约看到了。那时候我们在华为做自动驾驶，最痛苦的就是代码越写越多。

[02:35] **【陈亦伦】** 当时我们的规控（PnC）系统有 200 万行代码。你想想看，200 万行代码，每一行可能都是一个规则，或者是为了解决某一个极端案例（Corner Case）写的一个“补丁”。但这套系统它不 work，或者说它很难持续进化。只要环境稍微变一点，你就得再去堆代码。

[03:10] **【陈亦伦】** 后来我们就想，能不能换个思路？我们开始采集真实的人类驾驶数据。当时我带着团队去跑，采集了大量的真实轨迹。然后我们用一个神经网络去学习这些数据。最后的结果是，我们只用了大概 3 万行代码，就实现了过去那 200 万行代码的功能，而且在处理复杂路况时，它的表现更像“人”。那一刻，我觉得我找到了通往通用智能的钥匙，这不仅仅是自动驾驶，这其实就是具身智能的逻辑。

[04:20] **【程曼祺】** 那你觉得从自动驾驶跳到具身智能，这两者之间的逻辑转换是什么？

[04:45] **【陈亦伦】** 本质上都是 AI 在物理世界里的交互。只不过自动驾驶是在一个相对受限的二维平面（道路）上运动，而具身智能，或者说通用机器人，它需要处理的是三维空间里无穷无尽的交互。

[11:13] **【陈亦伦】** 我看到具身智能现在有三道曙光。第一道是强化学习（Reinforcement Learning）在运控（Locomotion）上的提升。以前机器人走路要写非常复杂的动力学方程，现在通过强化学习，机器人可以走得非常稳，甚至在碎石地上跑。

[12:30] **【陈亦伦】** 第二道曙光是 LLM（大语言模型）。它解决了机器人的任务规划（Task Planning）问题。你告诉它“给我拿杯咖啡”，它能理解这句话，并拆解成“找到咖啡机”、“拿杯子”、“按开关”等一系列动作。

[13:45] **【陈亦伦】** 第三道就是端到端（End-to-End）。它能解决最难的那些极端案例。当数据足够多的时候，模型自己就能学会如何应对那些没见过的场景。

[17:13] **【程曼祺】** 刚才你提到了“端到端”，现在行业里还有 VLA（Vision-Language-Action）模型，还有世界模型（World Model）。这几个概念，你觉得它们之间的联系和区别是什么？

[17:40] **【陈亦伦】** 那个，我觉得端到端是一个大的范式。VLA 更多是把视觉、语言和动作整合在一个架构里。而世界模型，是让机器人去“预测”未来。比如我推一下这个杯子，杯子会倒还是会滑走？机器人如果能在脑子里模拟这个过程，它的决策就会更高效。

[20:40] **【程曼祺】** 虽然有曙光，但你也提到了三道关卡。

[21:00] **【陈亦伦】** 对。数据、算法、后训练。具身智能现在其实还卡在第一道关卡：数据。

[24:43] **【陈亦伦】** 很多人在讨论算法架构，但我认为，最后能经受住大量数据冲刷的算法结构一定会非常简单。就像 GPT 并没有发明什么石破天惊的结构，它的伟大在于定义了训练任务是“预测下一个 Token”。

[30:16] **【陈亦伦】** 那么具身模型的训练任务是什么？我觉得是建立空间概念，以及学会跟世界交互。这需要的是真实的数据，而不是那种在仿真环境里造出来的“假数据”。

[40:54] **【程曼祺】** 说到数据，现在有很多流派。有人用仿真（Simulation），有人用 YouTube 视频。你为什么不看好这两者？

[41:20] **【陈亦伦】** 仿真数据有一个致命问题，就是 Sim-to-Real 的鸿沟。你在软件里模拟得再好，物理世界的摩擦力、柔韧性、光影变化都是不一样的。而视频数据呢，它只有视觉信息，没有“力”的信息。机器人看视频知道人在拿杯子，但它不知道人用了多大的力，手指是怎么微调的。

[49:42] **【陈亦伦】** 所以，真实数据只有两个源头：世界本身和人。为了获得最真实的数据，我们认为“可穿戴设备”是唯一的解。

[55:08] **【程曼祺】** 也就是你们现在在做的，让采集员戴上特制的手套和第一视角摄像头？

[55:25] **【陈亦伦】** 没错。我们开发了一套高精度的采集手套。采集员戴着它去干活，比如去组装线缆，去拿取易碎品。我们的传感器会记录下每一个关节的角度、力度。这种数据带有第一视角的视觉信息和精确的操作指令，这才是训练具身模型最肥沃的土壤。

[59:11] **【陈亦伦】** 具身智能这个领域，充满了硬件场景、本体、数据和算法之间的交替组合。中国在这方面有巨大的供应链优势和丰富的工厂场景优势。我们在它石智航做的，就是要把这些优势转化成数据资产。

[01:05:08] **【程曼祺】** 所以你们并没有简单地选择在已有的 LLM 上去做 VLA？

[01:05:30] **【陈亦伦】** 对。我们认为具身应该有自己的原生模型。虽然它可以借鉴语言模型的思想，但它处理的是物理世界的连续信号，而不是离散的单词。

[01:13:23] **【陈亦伦】** 从我们现在看到的数据增长趋势来看，具身智能已经到了 Scaling Law 的临界点了。只要数据量再上一个量级，机器人的泛化能力会有一个质的飞跃。

[01:18:04] **【程曼祺】** 听说它石现在选择的一个落地场景是处理柔性材料的线束装配？这听起来很难，因为线是软的，形状不固定。

[01:18:30] **【陈亦伦】** 是的，这在过去是机器人的禁区。但正因为难，它才具有最高的商业价值。如果机器人能处理好“软”的线束，那它处理绝大多数工业任务都不在话下了。

[01:21:15] **【陈亦伦】** 我觉得，能自己定义目标的具身公司才是真正靠谱的。在创业浪潮里，去“成为别人”往往不是一个好的选择。我们要做的就是用最笨的方法——采集最真实的数据，去攻克最难的场景。

[01:22:38] **【程曼祺】** 感谢亦伦今天的分享。从 3 万行代码的自动驾驶突破，到如今要在具身智能里寻找那个 Scaling Law 的爆发点，这是一段非常精彩的技术旅程。

[01:23:10] **【陈亦伦】** 谢谢曼祺，谢谢大家。

---
*(Transcription ends)*